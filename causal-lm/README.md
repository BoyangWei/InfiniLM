# 因果语言模型

## 介绍

因果语言模型（Causal Language Modeling）是一类预训练模型，它们的目标是从样本中学习语言的逻辑结构，从而根据前文预测下一个词的概率分布。这个 crate 定义了一种狭义的因果语言模型，具有以下特点：

1. 基于词（`token`）和词表（`vocab`）量化语言，词表有且仅有一个终结符（`eos`）；
2. 每层包含一次自注意力机制（`self-attention`）计算，能够感知一个有限的上下文容量（`max seq len`），并支持 KV Cache 加速；
3. 若存在某段文本 `[..p]` 区间的上文缓存，可通过输入 `[p..][..seq_len]` 区间的文本并估计 `[k..=p+seq_len]` 区间的词概率密度（k > p）。通常情况下 `k = p+seq_len`，即认为不可修改已存在的词，只预测新增的词；

   ```plaintext
   | t0 t1 t2 ... tp-1 | tp tp+1 ... tk-1 | tk ... tn-1 | tn |
   |<---- kv cache --->|<--------- query -|------------>|    |
                                          |<---- logits ---->|
   ```

4. 对于每个词表概率密度，采用随机采样法得到其中的一个词（贪心采样是 `top-k = 1` 的随机采样）；
